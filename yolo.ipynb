{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678b1642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (8.3.154)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from ultralytics) (2.2.5)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from ultralytics) (3.10.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from ultralytics) (4.11.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from ultralytics) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from ultralytics) (1.15.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from ultralytics) (2.7.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from ultralytics) (0.22.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\bikesh khyaju\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
      "Requirement already satisfied: filelock in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\bikesh khyaju\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d81baad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# print\n",
    "\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccffd992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8442a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('detection_image_2.jpg')\n",
    "model = YOLO('yolov8n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65eda544-2a07-4242-bba0-006e079e630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 1 person, 6 cars, 6 traffic lights, 121.4ms\n",
      "Speed: 3.9ms preprocess, 121.4ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "# Run YOLOv8 model prediction\n",
    "results = model.predict(source=image, save=False, imgsz=640, conf=0.25, device='cpu')\n",
    "# print(\"Detections:\", result[0].boxes)\n",
    "\n",
    "# Parse results\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy # (x1, y1, x2, y2)\n",
    "    scores = result.boxes. conf\n",
    "    class_ids = result.boxes.cls\n",
    "\n",
    "    for box, score, class_id in zip(boxes, scores, class_ids):\n",
    "        x1, y1, x2, y2=map(int, box)\n",
    "        label = model.names[int(class_id)]\n",
    "        confidence = float(score)\n",
    "    \n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0,255,0),2)\n",
    "        # Put label\n",
    "        cv2.putText(image, f'{label} {confidence :.2f}', (x1, y1-10),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Show the image\n",
    "cv2.imshow('YOL0v8 Detection', image)\n",
    "if cv2.waitKey(100000) & 0xFF == ord('q'):\n",
    "    print(\"Pressed q\")\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c43adf88-8d3a-403f-b4f5-cfc902d08678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use yolov8 pretrained model -- > make a streamlit -- > Give option to the user to use video cam (address 0) or upload a image\n",
    "# or upload a video -- > btn to run detection, space to show the detected (draw) results (image, video feed)\n",
    "# pushed in githubl\n",
    "# Humansignal Labelimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e37c4850-09c3-420f-ac0e-e634f206f89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.154  Python-3.12.11 torch-2.7.1+cpu CPU (12th Gen Intel Core(TM) i7-1255U)\n",
      " ProTip: Export to OpenVINO format for best performance on Intel CPUs. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
      "YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<1.18.0', 'onnxslim>=0.1.56', 'onnxruntime'] not found, attempting AutoUpdate...\n",
      "Collecting onnx<1.18.0,>=1.12.0\n",
      "  Downloading onnx-1.17.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting onnxslim>=0.1.56\n",
      "  Downloading onnxslim-0.1.57-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.22.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from onnx<1.18.0,>=1.12.0) (2.2.5)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from onnx<1.18.0,>=1.12.0) (6.31.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from onnxslim>=0.1.56) (1.14.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from onnxslim>=0.1.56) (24.2)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bikesh khyaju\\anaconda3\\envs\\ai_learning\\lib\\site-packages (from sympy->onnxslim>=0.1.56) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime)\n",
      "  Downloading pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading onnx-1.17.0-cp312-cp312-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 14.5/14.5 MB 2.1 MB/s eta 0:00:005\n",
      "Downloading onnxslim-0.1.57-py3-none-any.whl (154 kB)\n",
      "Downloading onnxruntime-1.22.0-cp312-cp312-win_amd64.whl (12.7 MB)\n",
      "   ---------------------------------------- 12.7/12.7 MB 2.9 MB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: flatbuffers, pyreadline3, onnx, onnxslim, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-25.2.10 humanfriendly-10.0 onnx-1.17.0 onnxruntime-1.22.0 onnxslim-0.1.57 pyreadline3-3.5.4\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  28.4s\n",
      "WARNING \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.57...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  30.5s, saved as 'yolov8n.onnx' (12.2 MB)\n",
      "\n",
      "Export complete (31.0s)\n",
      "Results saved to \u001b[1mC:\\Users\\Bikesh Khyaju\\Desktop\\bordway\\AI\\YOLO\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8n.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov8n.onnx'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the YOLOv8 model (can be 'yolov8n.pt', 'yolov8s.pt', or your custom model)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Export the model to ONNX\n",
    "model.export(format='onnx', opset=12, simplify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2ae5f-897d-4a12-8e0e-810b322a3e55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
